{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling with the new Gorilla model\n",
    "\n",
    "Copied and ajdusted from https://github.com/abacaj/openhermes-function-calling/tree/main\n",
    "Model: gorilla-llm/gorilla-openfunctions-v1\n",
    "Dataset: https://github.com/ShishirPatil/gorilla/tree/main/openfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "535201b2-95b7-4a5c-aa1b-5f95f9e695ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006627082824707031,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d41a2a74acf4dee8ce1ec9bcd6a40c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model_id = \"gorilla-llm/gorilla-openfunctions-v0\"\n",
    "ranker_id = \"cross-encoder/ms-marco-MiniLM-L-12-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16,device_map=\"auto\")\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Ranks functions descriptions based on their similarity to the query\n",
    "def rank_pipeline(model_id):\n",
    "  rank_model = CrossEncoder(model_id)\n",
    "  def rank(query, functions):\n",
    "    scores = rank_model.predict([(query, doc[\"description\"]) for doc in functions])\n",
    "    return functions[scores.argmax()]\n",
    "  return rank \n",
    "\n",
    "ranker = rank_pipeline(ranker_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4059915c-ce53-4178-9707-a930428254ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def generate_functions_prompt(query,functions=None):\n",
    "    prompt = f\"\"\"USER: <<question>> {query} <<function>> {json.dumps(functions)}\\nASSISTANT: \"\"\"\n",
    "    return  prompt\n",
    "\n",
    "def generate(prompt):\n",
    "    return pipe(generate_functions_prompt(prompt),max_new_tokens=512,do_sample=True,return_full_text=False)[0]['generated_text']\n",
    "\n",
    "def generate_ranked(prompt,functions):\n",
    "    fn = ranker(prompt,functions)\n",
    "    print(f\"using: {fn['name']}\")\n",
    "    prompt = generate_functions_prompt(prompt,[fn])\n",
    "    return generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"call_uber\",\n",
    "        \"description\": \"Find suitable ride for customers given the location, type of ride, and the amount of time the customer is willing to wait as parameters\",\n",
    "         \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"location of the starting place of the uber ride\",\n",
    "                },\n",
    "                \"ride_type\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\":  [\"plus\", \"comfort\", \"black\"],\n",
    "                    \"description\": \"types of uber ride user is ordering\",\n",
    "                },\n",
    "                \"time\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"the amount of time in minutes the customer is willing to wait\",\n",
    "                },\n",
    "                \"required\": [\"location\", \"time\"],\n",
    "\n",
    "            },\n",
    "         },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Gets the current weather for a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_weather',\n",
       " 'description': 'Gets the current weather for a given location',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'location': {'type': 'string',\n",
       "    'description': 'The city and state, e.g. San Francisco, CA'},\n",
       "   'format': {'type': 'string',\n",
       "    'enum': ['celsius', 'fahrenheit'],\n",
       "    'description': 'The temperature unit to use. Infer this from the users location.'}},\n",
       "  'required': ['location']}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker(\"What is the weather in New York?\",functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: get_current_weather\n",
      "get_current_weather(location=\"New York\", format=\"celsius\")\n"
     ]
    }
   ],
   "source": [
    "res = generate_ranked(\"What is the weather in New York?\",functions=functions)\n",
    "print(res.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: call_uber\n",
      "call_uber(location=\"94704\", ride_type=\"plus\", time=10)\n"
     ]
    }
   ],
   "source": [
    "res = generate_ranked(\"Call me an Uber ride in Berkeley at zipcode 94704 in 10 minutes\", functions=functions)\n",
    "print(res.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
